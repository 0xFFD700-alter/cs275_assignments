# 基本概念

OpenGL实际上是一种编程规范，即specification，由Khronos组织制定并维护
OpenGL只规定了每个函数该如何执行，但具体实现交由开发者决定，实现具体函数的往往是生产GPU的厂商（所以，OpenGL实际上并不是开源的）
OpenGL有许多的第三方库，很多第三方库是开源的，这些第三方库提供的实际上是底层OpenGL的抽象，OpenGL本身是一个底层API，非常的verbose，对它再进行一定的封装是有必要的
并且，OpenGL有跨平台的能力，不同平台的差异被第三方库abstract away了，第三方库封装了不同平台的不同处理逻辑，使得同一套代码能跨平台使用
此外，有一些OpenGL规范中未定义但十分有用的功能也由第三方库实现

核心模式和立即渲染模式：核心模式是现代OpenGL编程常用的方式，OpenGL开放了更多的接口，能让开发者进一步掌控细节，立即渲染模式是较老的开发模式，使用起来很方便，但是很多功能都没法自定义

# 上下文和状态机

把整个OpenGL框架理解成一个状态机（文档中也把状态或者有关的概念称为上下文context）
状态设置函数：state-changing——用于设置改变OpenGL Context
状态使用函数：state-using——根据当前状态执行动作

# GLFW + GLAD

首先需要创建一个窗口和一个OpenGL上下文，OpenGL有意将创建窗口这个操作抽象出去，让用户自己处理（它应该在不同平台有不同的表现），GLFW封装了这个部分，GLFW提供了创建一个窗口和一个OpenGL context的接口，用来完成之后的渲染

另外，OpenGL只是一个规范，具体的实现是由显卡厂商或者显卡驱动开发商完成的，OpenGL的驱动版本众多，大多数函数的位置没法在编译时确定下来，需要在运行时查询，所以开发者需要获取函数指针并将它保存下来以供之后使用，代码写起来很麻烦，但好在GLAD能简化这个过程，可以自动获取函数

**需要确保在include GLFW之前已经include了GLAD（把include GLAD写在include GLFW上面），GLAD头文件包含了所需要的OpenGL头文件**

# CMake

用别人的源代码的时候，可以用预编译好的二进制文件，也可以自己进行源编译，自己进行源编译的好处是，编译好的库可以完全适配自己的操作系统和CPU，有时候，直接使用别人编译好的二进制文件会出现问题
如果需要自己编译别人的源代码，那么可能需要自己构建项目，比如使用Make，但是在不同的系统和IDE上构建的方式很不一样，自己写Makefile是一件十分繁琐的工作
CMake解决了这个难题，CMake是一个工程文件生成工具，不论你用什么平台或者IDE，你都可以从更抽象的层次上定义CMake脚本（不管用什么系统或者IDE，只用自定义构建项目的逻辑），CMake脚本都能帮你生成Makefile（它也能生成如vs的sln项目文件，用于在vs里构建项目）

CMake的工作过程通常分为两步，1）配置configure：用CMakeLists.txt来控制配置的过程，这部分操作需要指定源文件目录（源文件称作source tree）和生成二进制可执行项目文件（Makefile, .sln, .xcodeproj）的目录（项目文件称作build tree），生成的可执行文件一般存放在一个叫做build的目录里，build里的文件定义了build pipeline，即目标程序应该怎么进行编译和链接；2）生成generate，用本地的构建工具来操作build里的可执行文件，进行编译和链接，根据用户编写的程序生成需要的库或者可执行文件（不同平台的编译和构建工具多种多样，CMake同样把这个部分统一了，帮你用各种命令调用他们，用户不必关注编译和构建工具的各种细节）

# 图形渲染管线

![](https://learnopengl-cn.github.io/img/01/04/pipeline.png)
OpenGL使用图形渲染管线（graphics pipeline）来把3D图像显示在2D屏幕上，上图包含了graphics pipeline的两个主要部分，1）上面部分，把3D坐标转换为2D坐标；2）把2D坐标转换为实际有颜色像素

pipeline由一个个着色器（shader）构成，着色器是用GLSL（OpenGL shading language）写成的，管线中的每个阶段都是高度专门化的，能够很容易地并行执行，GPU内成千上万的小处理核心各自运行着自己的shader，从而快速处理图像数据

图中标记为蓝色的部分的shader能让开发者自行配置，图中，最初始的输入数据是vertex data，vertex data是一个vertex的集合，一个vertex是一个3D空间中的顶点，vertex的数据是用vertex attribute表示的，理论上可以用很多方式来表示vertex attribute，即你可以自定义每个vertex应该包含哪些数据，但通常，vertex只有四个维度，即只设定每个vertex的xyz坐标和颜色就可以了

为了让OpenGL知道我们希望把vertex data渲染成单独的点，还是mesh化的三角形，或者是一条长长的线，需要在绘制时把图元（primitive）传递给OpenGL，例如：图元包含GL_POINTS,GL_TRIANGLES,GL_LINE_STRIP，即最基本的点，三角形和直线

接下来简要说明pipeline中的各个部分分别完成了什么工作：
1. 顶点着色器（vertex shader）：进行3D坐标转换，把OpenGL所用的标准化设备坐标（Normalized Device Coordinates）转化到屏幕空间坐标（Screen-space Coordinates），标准化设备坐标把整个空间限制在-1到1之间（xyz三个坐标轴的范围都是-1到1），顶点着色器通过glViewport函数提供的数据进行视口变换，把设备坐标里的点映射到屏幕的显示范围里

2. 图元装配（primitive assembly）：把顶点着色器的顶点装配成指定的形状，构造点与点之间的边或者其他形状

3. 几何着色器（geometry shader）：可以通过产生新的顶点来构造出新的图元，能够生成其他形状，途中的几何着色器生成了另一个三角形

4. 光栅化（rasterization）：把图元映射为屏幕上对应的像素点，生成片段（fragment），并且进行裁切，把视图之外的所有像素点全部丢弃，一个fragment是OpenGL用于渲染一个像素点所需的全部数据

5. 片段着色器（fragment shader）：计算产生像素的最终颜色，片段着色器包含了各种3D场景中的数据，比如光照，阴影等等

6. Alpha测试与混合（blending）：检测fragment对应的深度，即判断物体之间的透视遮挡关系，如果一个物体被其他物体所遮挡，那么它应该被丢弃，此外，这个阶段还会检测alpha值，即物体的透明度（**实际上是不透明度，取值范围在0到1之间，alpha值越高越不透明**），并且对物体进行blend

# 第一步：编写着色器

现代OpenGL编程中，至少需要定义一个顶点着色器和片段着色器，几何着色器是可选的，可以使用系统默认配置的几何着色器

OpenGL的着色器对象都用一个无符号整型作为标识符，使用这个标识符结合OpenGL函数可以对着色器进行操作，着色器可以写在一个C风格的字符串中，然后在编译着色器的时候传入字符串指针的指针

通常也需要检测编译是否成功，同样使用整型变量来获取编译状态信息

着色器是运行时实时编译的，编译完成后，需要把着色器连接（Link）为一个着色器程序对象（Shader Program Object），着色器程序对象同样有一个无符号整型标识符（**注意：链接的过程要遵循一定的顺序**，如果前一个着色器的输出和下一个着色器的输入不匹配，那么会得到一个链接错误）

使用glUseProgram激活着色器程序对象，之后每当渲染管线调用着色器时，都会使用之前写好的着色器，**在激活着色器程序对象之后，需要delete之前的着色器对象**

# 第二步：解释顶点属性

顶点着色器理论上能接受任何格式的顶点属性，但同时，也意味着需要手动指定需要怎么解释输入数据

VBO（vertex buffer object）顶点缓冲对象

VAO（vertex array object）顶点数组对象

EBO（element buffer object）元素缓冲对象

这三个对象也有一个无符号整型作为标识符


0：复制顶点数组到缓冲

1：设置顶点属性指针

2：着色器程序

3：绘制物体

VBO，缓冲，包含具体的点的数据，包含要传给顶点着色器的真实数据

VAO，控制了“上下文”（准确地说是“下文”），VAO可以记住解释顶点属性（vertex attribute）的代码部分

***可以认为，VBO决定了数据的具体位置，而VAO决定了要怎么画这些数据***，事实上不用VAO我们也能直接用VBO里的数据来绘制，**但是VAO提供了一个方便的接口来让我们存储这个绘制的流程，需要重复绘制时，只用bind相应的VAO就行了**

EBO，缓冲，又称为索引缓冲，可以指定要绘制的mesh的顶点（直接指定VBO里的索引），OpenGL来自动判断哪些点会重复，避免产生额外开销

和VBO一样，VAO也能记录EBO的信息，绘制的时候调用VAO即可，统一使用VAO来记住**怎么绘制**

通常的流程是这样的：
1. bind一个VAO
2. bind一个VBO并且把数据复制到buffer中
3. （可选步骤）bind一个EBO并且把数据复制到buffer中
4. 设置顶点属性指针

# 着色器

着色器是相对独立的程序，它们之间是不能通行的，唯一的沟通方式是输入和输出

## 如何使用GLSL（OpenGL Shading Language）：

GLSL是为图形计算量身定制的，语法比较像C，有一些针对向量和矩阵运算的有用特性

GLSL开头总是声明版本，然后定义输入变量和输出变量，最后是uniform变量，每个着色器的入口都是一个main函数，main函数接收输入变量，并把处理的结果输出到输出变量中（注：这些输入输出变量是抽象的，可以理解为函数的形参）

main函数的返回类型可以是void，也可以是int

特别地：在谈论<u>***顶点着色器时，每一个输入变量都称为一个顶点属性***</u>，一般至少有16个包含四个分量的顶点属性可用，可以通过GL_MAX_VERTEX_ATTRIBS来查看顶点属性数量的上限

数据类型可以是C的基本类型或者是GLSL定义的容器，即vector和matrix，容器中包含了多个基本类型变量，例如vector，通常记为vec\[n\]，n是一个需要写出来的数字，可以是2，3或者4，如果vector包含其他类型，那么可以声明为：ivec\[n\]（整数向量），dvec\[n\]（双精度浮点数向量）等等

默认的vec\[n\]使用单精度浮点型，与结构体的使用方式类似，使用vec.x, vec.y vec.z, vec.w来依次获取向量的各个分量

向量的声明是一个构造函数，向量还支持重组语法（swizzling）

**顶点着色器的输入比较特别**（这是整个着色器程序的第一个输入），要指定元数据layout (location = 0)来设置***属性位置值***，每个输入变量都对应着一种顶点属性，这个属性位置值，主要在设置顶点属性指针的时候使用，即调用glVertexAttribPointer和glEnableVertexAttribArray时

理论上，VBO可以存储任何数据，即可以把任何我们觉得有用的数据复制到显存中，glVertexAttribPointer告诉了顶点着色器该如何读取这些用户定义的最原始的输入数据

- 每次调用glVertexAttribPointer(index, size, type, normalized, stride, pointer)时，可以理解为：

    - 把读取的数据当作location=index对应的顶点属性，每次读取size个，数据类型是type，根据normalized决定是否要归一化到-1,1之间，连续两次读取间隔了stride个字节，第一次读取的位置指针是pointer

- 更具体地说，如果内存位置是以字节为单位指定的，那么glVertexAttribPointer(index, size, type, normalized, stride, pointer)的读取方式是：

    - 从pointer所指向的字节开始读，每次读取size*sizeof(type)个字节，相邻两次读取间隔了stride个字节，读取的输入作为location=index的顶点属性

**片段着色器的输出比较特别**（这是整个着色器程序最后的输出），它是一个vec4，指定了渲染的颜色和alpha值（不透明度）

Uniform是GLSL中的全局变量，不同的着色器都可以访问这个全局变量，它在每个着色器程序对象中必须是独一无二的

Uniform可以把数据从CPU发往GPU，在C++代码里（不是GLSL里）用glGetUniformLocation来获取Uniform变量的地址

在外面的代码里（C++里，非GLSL），可以在获得着色器程序对象之后的任意时刻获取Uniform变量的地址，**但是如果要操纵Uniform变量，需要先激活着色器程序对象**

OpenGL的核心是一个C库，不支持函数重载，所以要根据不同的使用类型定义多个不同的函数，例如，如果想给Uniform变量设置值，那么根据使用类型，需要调用glUniform4f（函数可以传递四个float类型的数据给Uniform变量），或者glUniformui（函数给Uniform变量传递一个无符号整型），或者glUniformfv（函数给Uniform变量传递一个向量或者数组）

自然地，可以在一个数组里添加更多的数据，定义更多的顶点属性，并把它们通过VBO一次性传输到显存中

如果给三角形的每个顶点都定义了一个颜色，那么最终画出来的三角形是彩色的，像调色板一样，这是因为片段着色器会进行片段插值，差值的每个单位是一个光栅，光栅化阶段会形成光栅，光栅会根据每个片段在三角形上的相对位置来决定这个片段对应在屏幕上的绝对位置

片段插值的方式是线性的，**对片段着色器的所有输入属性都会进行片段插值**

# 纹理

如果要指定每个顶点的颜色，当顶点很多时非常麻烦，但可以插入一张图片，图片上原本具有足够多的细节，把图片贴合到3D模型上

纹理有自己的一套坐标，即Texture Coordinate，范围是\[0,1\]，(0,0)在左下角，(1,0)是水平轴，即x轴的右边

我们需要告诉片段着色器如何确定三角形顶点和纹理图片的坐标关系，使用纹理坐标获取纹理颜色的过程叫做采样（Sampling），对于超出纹理坐标的部分，可以用其他方式来设置纹理环绕方式（wrapping），如重复，镜像，clamp to edge，clamp to border等，默认的环绕方式是镜像

![](https://learnopengl-cn.github.io/img/01/06/texture_wrapping.png)

使用glTexParameter*函数对一个纹理坐标轴设置环绕方式，纹理坐标轴的名称是s,t,r，这分别对应着实际三维坐标的x,y,z

纹理图片是有分辨率的，OpenGL需要根据设置的纹理坐标来对纹理图片上的像素进行采样，提取纹理像素的颜色，如果纹理图片分辨率和实际的物体大小不一样，那么可以对纹理进行过滤（texture filtering）

纹理过滤的主要方式有两种，即GL_NEAREST和GL_LINEAR

- GL_NEAREST会根据纹理坐标选择距离这个纹理坐标最近的纹理图片上的像素点作为采样像素点

    - GL_NEAREST会产生颗粒状的图案，边缘锯齿会更明显，比较像8-bit风格

- GL_LINEAR会根据纹理坐标选择这个纹理坐标附近的一些像素点进行加权平均，和线性插值的方式类似，返回的采样像素点是附近像素点的混合色

    - GL_LINEAR会blur原本的纹理图片，产生的效果更加平滑

根据需要（放大或者缩小，magnify或者minify），可以提前使用glTexParameter*设置纹理的过滤方式

考虑到真实场景中的透视关系，远处的物体比较小，它会在高分辨率纹理上大跨度地采样像素，近的物体比较大，会对纹理进行更加精细地采样，这使得纹理采样变得比较困难

为了解决这个问题，OpenGL使用多级渐远纹理（Mipmap）来解决这个问题，mipmap会产生一系列的纹理图片，前一个纹理图片是后一个纹理图片大小的1/2

可以使用GL_\[filter1\]\_MIPMAP\_\[filter2\]来指定多级渐远纹理的过滤方式，filter可以设置为NEAREST或者LINEAR，filter1指定了mipmap中的某一个纹理上的采样方式，filter2指定了在mipmap中多个不同的纹理上的采样过度方式

**使用多级渐远纹理时，只可以将多级渐远纹理设置到纹理被缩小的情况（必须是“渐远”的）**，纹理放大时的纹理过滤方式不可以使用mipmap

图片的y轴原点通常在图片顶部，但是OpenGL的y轴原点在底部，往往在读取纹理图片的时候需要翻转一下

应用纹理时，主要调用片段着色器中的texture函数，texture函数的第一个输入是纹理采样器，第二个输入是对应的纹理坐标，通常顶点着色器处理输入数据，输出纹理坐标，这样把纹理坐标传入片段着色器中

# 变换

为什么需要使用四维坐标来操作三维向量，这是为了更好地并行，统一旋转和平移两个变换，都可以写成矩阵乘法

并且，设定第四个分量还有额外的好处，能处理深度有关的信息，解决透视遮挡问题

注意：当写旋转矩阵时，在三维空间中，可以单独沿着x，y或者z轴旋转，任何的一个旋转也可以写成多次矩阵乘法，即先沿着x轴再沿着y轴旋转等等，但是，这么做会导致一个万向节死锁问题（Gimbal Lock），为了解决这个问题，更好的方法是直接使用沿着任意轴旋转的旋转矩阵，任意轴旋转矩阵的推导方式：

1. 给定任意旋转轴**单位向量**$n$，求任意一个向量$v$在$n$上的投影$n_{||}$，即$v_{||} = (v \cdot n)n$，$v$垂直于$n$的分量是$v_{\bot} = v - v_{||} = v - (v \cdot n)n$

2. 求$v_{\bot}$和$n$的叉乘$w$，$w = v_{\bot} \times n = v \times n$，$v_{\bot}$和$w$构成了一个二维的坐标系，在这个坐标系里让$v_{\bot}$方向上的向量逆时针旋转$\theta$（**顺着$n$的指向看，旋转方式是逆时针**）后得到的向量是$v'_{\bot} = v_{\bot} \cos\theta + w \sin\theta$

3. 最后，把旋转过的$v_{\bot}$分量和不旋转的$v_{||}$分量加起来，整理得到旋转后的$v'$，$v' = \cos\theta(v - (v \cdot n)n)+\sin\theta(v \times n)+(v \cdot n)n$

4. 得到了任意向量的旋转变换结果之后，可以写出投影矩阵和叉乘的矩阵表示，加起来得到最终的绕任意轴的旋转矩阵（叉乘的矩阵，绕轴旋转的无穷小生成元）

**真正能够避免万向节死锁的方式是使用四元数（Quaternion）**，四元数的计算方式更加安全，并且效率更高

如果要让图形随着渲染循环不断进行变换，产生动画效果，似乎主要使用的方式是uniform变量，并且每次循环都对这个uniform变量进行重新赋值

如果对图形进行变换的矩阵是一个uniform变量，那么在使用glm对这个变换矩阵进行操作时，操作的顺序是从左到右，即先写的操作是后执行的，***每次有新的变换作用在这个uniform矩阵上时（新的操作也是矩阵）新操作的矩阵会右乘到原来的矩阵上***，所以最后作用到向量上时，先写的操作会后执行，后写的操作会先执行

在着色器中使用矩阵进行操作也能节省处理时间，**不要频繁地在CPU里处理数据然后发送给GPU（这个IO是非常慢的）**

## 什么是万向节死锁（Gimbal Lock）

待续

## 欧拉角和四元数

欧拉角：定义三维空间里两个坐标系的相对位置关系（两个坐标系原点相同）可以用三个角来定义，即：yaw，roll和pitch

待续

# 坐标系统
OpenGL使用标准化设备坐标，三个轴的坐标都在-1,1之间，通常可以自己设定一个坐标，然后在把数据传入顶点着色器时把它归一化

事实上，OpenGL内部处理时使用多种不同的坐标系，各个坐标系对不同操作和运算有不同的相应优势，通常，有这五个坐标系统：

1. local space
2. world space
3. view space
4. clip space
5. screen space

经过上面五个坐标系统的处理后，才能在屏幕上输出图像，坐标变换需要用到变换矩阵，最重要的三个变换矩阵分别是：

1. model matrix
2. view matrix
3. projection matrix

坐标系统和变换矩阵的关系如下图：

![](https://learnopengl-cn.github.io/img/01/08/coordinate_systems.png)

1. 局部坐标是对象相对于局部原点的坐标，也是单个物体自己起始的坐标
2. 下一步是将局部坐标变换为世界空间坐标，世界空间坐标是处于一个更大的空间范围的。这些坐标相对于世界的全局原点，它们会和其它物体一起相对于世界的原点进行摆放
3. 接下来我们将世界坐标变换为观察空间坐标，使得每个坐标都是从摄像机或者说观察者的角度进行观察的
4. 坐标到达观察空间之后，我们需要将其投影到裁剪坐标。裁剪坐标会被处理至-1.0到1.0的范围内，并判断哪些顶点将会出现在屏幕上
5. 最后，我们将裁剪坐标变换为屏幕坐标，我们将使用一个叫做视口变换(Viewport Transform)的过程。视口变换将位于-1.0到1.0范围的坐标变换到由glViewport函数所定义的坐标范围内。最后变换出来的坐标将会送到光栅器，将其转化为片段

model matrix对物体进行位移，缩放，旋转，把物体放置到world space的真实位置上

view space是用户观察到的空间，想象用户通过一个摄像机来观察整个世界，需要把world space进行位移和旋转变换，把能看到的物体变换到摄像机的前方

## clip space

### 将4D的view space坐标映射到clip space的过程称为<u>投影</u>（这个过程主要将坐标限制在frustum之内，frustum之外的点被clip掉了），投影之后，把w坐标归一化，才转化为了<u>3D的标准化设备坐标</u>

clip space会裁剪所有处于坐标范围外的点（**这些坐标变换都是为了渲染而服务的，不会出现在可视范围内的物体不需要渲染出来，以节省计算资源**），被裁剪掉的点会被忽略

**clip space真正完成了从自定义坐标空间到标准化坐标空间的映射（-1到1之间）**，projection matrix完成了这个工作，在作用投影矩阵之后，任何在-1,1之外的点都会被裁剪掉（**如果某个图元，比如三角形的一部分被裁剪掉了，那么OpenGL会重构这个三角形为多个三角形来适应裁剪范围**）

投影矩阵会创建一个观察箱（viewing box），这个box被称为Frustum，只有在Frustum之内的点才会被最终渲染到屏幕上，**把特定的坐标转化为标准化设备坐标的过程被称为投影**

当所有的点被投影到clip space里之后，***最终会执行透视除法（perspective division），用xyz分量除以w分量，<u>将4D的clip space坐标</u>转变为3D的标准化设备坐标，这一步在顶点着色器的最后被自动执行***

要注意：对物体进行变换（平移，旋转）的操作一般是在顶点着色器中完成的，在经过顶点着色器之后，w会被归一化为1

projection有两种方式，分别是正射投影和透视投影，正射投影形成的frustum是一个长方体，创建投影矩阵时需要指定这个frustum的长宽高，**实际上要指定的是近平面，远平面和平面的宽高**，使用glm::ortho来创建一个正射投影矩阵

![](https://learnopengl-cn.github.io/img/01/08/orthographic_frustum.png)

透视投影除了将给定的坐标映射到clip space之外，还会修改每个点的w分量，离观察者越远，w分量就会越大，归一化后的xyz坐标值就会越小，达成近大远小的效果，**w分量对实现透视效果也非常重要**，此时frustum的形状是一个棱台

用glm::perspective可以创建一个透视frustum，需要定义fov值（field of view），fov值是透视投影射出的两根线之间的张角，之后要设定平面的宽高比，最后设定近平面和远平面的位置

![](https://learnopengl-cn.github.io/img/01/08/perspective_frustum.png)

近平面一般位置设定在0.1，远平面一般位置设定在100.0，只有在这两个平面内的物体会被渲染，如果把近平面的距离设定得比较大，比如10.0，**那么当摄像机靠近物体时，这个物体不会被渲染出来，视线会穿过去**（游戏中常见得效果）

经过前面三个矩阵的处理，即model，view，projection matrix之后，***最后顶点坐标才会被赋值到顶点着色器的gl_Position中（这三个坐标变换都在顶点着色器之前执行）***，然后进行透视除法

最后，OpenGL使用glViewPort将标准化设备坐标映射到screen space，将坐标和屏幕像素关联起来

## 标准化设备坐标

OpenGL使用的是右手系，屏幕右边是x轴正方向，屏幕上边是y轴正方向，从屏幕里指向屏幕外是z轴正方向，为了体现出3D效果，通常需要先将坐标系沿着x轴进行旋转

## Z-buffer

在3D世界中，还要考虑物体之间的遮挡关系，实际上，这相当于决定物体的先后渲染顺序，后渲染的物体会遮挡住先渲染的物体，所以应该先渲染离摄像机远的物体，这样离得近得物体能够正确遮挡离得远得物体

OpenGL使用Z-buffer来决定是否需要覆盖一个像素，每一个片段都有一个z值，当需要渲染一个片段时，会把这个片段的z值与z-buffer进行比较，如果这个片段被某些片段覆盖了，那么会丢弃这个片段，否则这个片段会被渲染出来覆盖其他的片段，**z-buffer的大小应该与像素点总数相当，z-buffer需要记录每个像素点上被渲染片段的最小z值（距离视点最近）**，每当需要渲染一个片段时，比较这个片段的z值与z-buffer在对应像素上已经存储的z值，如果新片段的z值比z-buffer里存储的z值更小，那么说明这个片段离视点更近，需要渲染这个片段来覆盖之前的片段

每次渲染循环开始时，都需要清除上一帧的z-buffer，使用glClear函数来清除z-buffer，glClear函数接受的参数是所有需要清除的bit的“按位或”，GL_COLOR_BUFFER_BIT清除的是屏幕上的所有颜色，GL_DEPTH_BUFFER_BIT清除的是z-buffer

使用glEnable函数来开启OpenGL的深度检测功能

另外，如果需要在多个不同的位置上渲染同一个物体，只需要把这个物体进行多次变换，然后调用glDrawArrays就行了

# 摄像机

OpenGL本身没有摄像机的概念，实际上摄像机的移动可以等价于物体的反向移动，让物体朝着相反的方向移动来模拟出摄像机，产生一种观察者的视点在移动的感觉

摄像机/观察空间实际上是以摄像机为原点，把世界坐标变换为相对于摄像机的坐标

使用glm::lookAt可以创建一个LookAt矩阵，这个矩阵的作用是把世界坐标变换到观察空间坐标（即以摄像机为原点的坐标），这个函数的输入是glm::lookAt(position, target, up)，即摄像机位置position，摄像机看向的坐标target和世界坐标的上方向单位向量，glm通过向量叉乘的方式自动构建一个以摄像机为原点的坐标系

可以获取鼠标和键盘输入来移动摄像机的视角，通常键盘控制摄像机的position，鼠标控制摄像机的target方向，滚轮控制缩放

在使用键盘和鼠标控制摄像机视角时，需要在移动速度上乘以计算出渲染每一帧的时间（**即渲染循环运行一轮的时间**），这么做是因为，为了适应不同硬件设备的性能不同，渲染时间有快有慢，如果渲染得慢，那么间隔时间长，最后移动的距离就大，渲染快，间隔时间短，那么移动距离就小

**滚轮控制缩放实际上是控制投影frustum的fov值，即field of view，不论fov有多大，近平面都会完整地显示在屏幕上，但屏幕大小是固定的**，所以，如果增大fov，近平面变大，渲染的范围变大，会有视角远离的感觉，如果减小fov，近平面变小，渲染的范围变小，会有视角拉近的感觉